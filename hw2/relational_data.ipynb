{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Data and Visualization [30pts]\n",
    "In this problem, you will be analyzing the Twitter data we extracted using [this](https://dev.twitter.com/overview/api) api. The data consists of Twitter users (with unique handles) and their attributes (e.g., number of followers), some recent tweets posted by them with attributes (e.g., time stamp, number of retweets), and the follow relationship between the users. These are available in the three CSV files provided to you:\n",
    "- users.csv - users, user attributes\n",
    "- edges.csv - follow edges (directed, an edge from A to B means A follows B or B is a friend of A)\n",
    "- tweets.csv - tweets posted by the users along with its attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Relational Data [5pts + 6pts + 6pts]\n",
    "This question will guide you through loading Twitter data into an in-memory SQLite database and running some basic queries on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task A: Load Twitter data into SQLite database [5pts]\n",
    "Your first task is to use the csv and sqlite3 python packages to load the three csv files we give you as relations (or tables) into an SQLite in-memory database.\n",
    "\n",
    "Loading the data from csv file into the database involves the following steps:\n",
    "1. Identify the schema of the table (for this problem, you will only need TEXT and INTEGER attribute types)\n",
    "2. Create a table with the identified schema\n",
    "3. Load the contents of csv in memory\n",
    "4. Insert every row of csv file as a record in the table\n",
    "\n",
    "You can refer to [sqlite3 documentation](https://docs.python.org/2/library/sqlite3.html) and the class lecture for steps 2 and 4. For step 3, refer to the [csv documentation](https://docs.python.org/2/library/csv.html). Be sure to name your tables `users`, `edges`, and `tweets`. \n",
    "\n",
    "Make sure to commit (the equivalent of Ctrl+S for databases) any changes you make to the database. [This](https://www.techopedia.com/definition/16/commit) page should give you an idea about why commit is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twitter_data_sqlite3(conn, users_filepath, edges_filepath, tweets_filepath):\n",
    "    \"\"\" Load twitter data in the three files as tables into an in-memory SQLite database\n",
    "    Input:\n",
    "        conn (sqlite3.Connection) : Connection object corresponding to the database; used to perform SQL commands.\n",
    "        users_filepath (str) : absolute/relative path to usersCopy.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edgesCopy.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweetsCopy.csv file\n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    ## users table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE users (\n",
    "        name TEXT,\n",
    "        screen_name TEXT, \n",
    "        location TEXT, \n",
    "        created_at TEXT, \n",
    "        friends_count TEXT, \n",
    "        followers_count TEXT, \n",
    "        statuses_count TEXT, \n",
    "        favourites_count TEXT\n",
    "    );\"\"\")\n",
    "    \n",
    "    \n",
    "    ## edges table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE edges (\n",
    "        screen_name TEXT,\n",
    "        friend TEXT\n",
    "    );\"\"\")\n",
    "    \n",
    "    \n",
    "    ##tweets table\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE tweets (\n",
    "    screen_name TEXT,\n",
    "    created_at TEXT,\n",
    "    retweet_count TEXT,\n",
    "    favorite_count TEXT,\n",
    "    text TEXT\n",
    "    );\"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    with open(users_filepath) as users_csv:\n",
    "        users_file = csv.reader(users_csv)\n",
    "        count, iterat = 0, 0\n",
    "        for row in users_file:\n",
    "            if (count == 0): # ignore column names \n",
    "                count = 1\n",
    "                continue\n",
    "            cursor.executemany(\"INSERT INTO users VALUES (?,?,?,?,?,?,?,?)\", [tuple(row)]) \n",
    "    \n",
    "    \n",
    "    with open(tweets_filepath) as tweets_csv:\n",
    "        tweets_file = csv.reader(tweets_csv)\n",
    "        for row in tweets_file:\n",
    "            cursor.executemany(\"INSERT INTO tweets VALUES (?, ?, ?, ?, ?)\", [tuple(row)])\n",
    "        \n",
    "    with open(edges_filepath) as edges_csv:\n",
    "        edges_csv = csv.reader(edges_csv)\n",
    "        for row in edges_csv:\n",
    "            cursor.executemany(\"INSERT INTO edges VALUES (?, ?)\", [tuple(row)])\n",
    "    conn.commit()\n",
    "    \n",
    "          \n",
    "        \n",
    "        \n",
    "def main():\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    c = load_twitter_data_sqlite3(conn, users_filepath, edges_filepath, tweets_filepath)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function will be called as in the cell below. The cell also contains some test code to display all tables in the database. You may want to write you own tests for the individual tables to verify that the data has been loaded properly. (e.g., number of tuples in each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('users',)\n",
      "('edges',)\n",
      "('tweets',)\n"
     ]
    }
   ],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "# connect to an in memory database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "conn.text_factory = str\n",
    "# call to your function\n",
    "load_twitter_data_sqlite3(conn, 'users.csv', 'edges.csv', 'tweets.csv')\n",
    "# make sure to change the path to csv files appropriately\n",
    "cursor = conn.cursor()\n",
    "# prints all tables in the database\n",
    "for row in cursor.execute(\"SELECT name FROM sqlite_master WHERE type = 'table';\"):\n",
    "    print (row)\n",
    "# for row in cursor.execute('SELECT * FROM tweets'):\n",
    "#         print (row)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task B: Trending tweets in a topic [6pts]\n",
    "Twitter is regarded as an invaluable source of valuable information. Hence, one of the favorite tasks of data miners is the analyse the trending tweets in a given topic.\n",
    "\n",
    "This task requires you to retrieve the top N most trending tweets (in descending order of trending_score) about a given topic (which is a list of keywords). The following information may be useful:\n",
    "\n",
    "- A tweet is said to be about a given topic if it contains any of the given topical phrases/keywords.\n",
    "- We will use the following simple trending_score: retweet_count + favorite_count. Tweets with higher trending_score must be ranked before the ones with lower trending_score.\n",
    "- Your result must contain unique tweets. If a tweet text occurs multiple times, display it only once with its highest trending_score.\n",
    "- Break ties by sorting the tweets in alphabetical order.\n",
    "\n",
    "The output schema should be as follows:\n",
    "\n",
    "|tweet (TEXT)| trending_score (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trending_tweets(cursor, topical_phrases=['Hillary', 'Clinton'], N=5):\n",
    "    \"\"\" Retrieves the top N trending tweets containing one or more of the given topical phrases.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "        topical_phrases (list of strings): A list of keywords identifying a topic.\n",
    "        N: Number of trending tweets to retrieve\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    query = \"SELECT DISTINCT text, (retweet_count + favorite_count) FROM tweets WHERE (text LIKE '%Hillary%' OR text LIKE '%Clinton%') AND (retweet_count + favorite_count) <= (SELECT MAX(retweet_count + favorite_count) from tweets WHERE retweet_count IN (SELECT CAST(retweet_count AS INT) FROM tweets) AND favorite_count IN (SELECT CAST(favorite_count AS INT) FROM tweets)) ORDER BY ((retweet_count + favorite_count)) DESC limit 5\"\n",
    "    results = cursor.execute(query)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    cursor = conn.cursor()\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    load_twitter_data_sqlite3(conn, users_filepath,edges_filepath, tweets_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default inputs to the function will retrieve 5 trending tweets about topic Hillary Clinton. You can view the output of your query using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "# results = trending_tweets(conn.cursor())\n",
    "# for row in results:\n",
    "#     print (row)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Task C: Tweet recommendation [6pts]\n",
    "How does Twitter go about populating the feed for a user? While Twitter may use a comple models to do this, in this task, we will use a Simple Tweet Recommender (STR), which recommends a user's tweets to all users who follow him/her (without checking for possible duplicates; i.e., STR may recommend the same tweet twice if two of a user's friends have posted it).\n",
    "\n",
    "In this task, you will write a query to determine the number of tweets recommended to each user. Use only the snapshot of edges and tweets we have provided to you to do the recommendation. Report the results on the users present in the users table. (Hint: The number of records in your output should match that in the \"users\" table.) The order of results does not matter.\n",
    "\n",
    "The output schema should be:\n",
    "\n",
    "|screen_name (TEXT)| num_tweets (INTEGER) |\n",
    "| :--- |:--- |\n",
    "| | | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNRESOLVED\n",
    "\n",
    "def num_tweets_in_feed(cursor):\n",
    "    \"\"\" Retrieves the number of tweets STR recommends to each Twitter user.\n",
    "    Input:\n",
    "        cursor (sqlite3.Cursor): Cursor object to query the database.\n",
    "    Output:\n",
    "        results (sqlite3.Cursor): Cursor object which can be used to iterate over the retrieved records/tuples.\n",
    "    \"\"\"\n",
    "    query = \"\" # your query here\n",
    "    return cursor.execute(query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = sqlite3.connect(\":memory:\")\n",
    "    cursor = conn.cursor()\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "    load_twitter_data_sqlite3(conn, users_filepath,edges_filepath, tweets_filepath)\n",
    "    i = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    for row in cursor.execute(\"SELECT screen_name from tweets WHERE (SELECT COUNT(*) from tweets) > 5491\"):\n",
    "        print(row)\n",
    "        if i > 100000:\n",
    "            break\n",
    "        i = i + 1\n",
    "    print(i)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Visualization [2pts + 7pts + 4pts]\n",
    "In this question, you will load all data into pandas dataframes and analyse (and visualize!) some interesting trends using [matplotlib](http://matplotlib.org) python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task A: Load Twitter data using pandas [2pts]\n",
    "Fill in the following method stub and return the data frames for users, edges and tweets.\n",
    "\n",
    "Pandas will treat missing values as NaNs by default. However, for this assignment, you should treat missing values (i.e., empty strings in the csv files) as empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "def load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath):\n",
    "    \"\"\" Loads the Twitter data from the csv files into Pandas dataframes\n",
    "    Input:\n",
    "        users_filepath (str) : absolute/relative path to users.csv file\n",
    "        edges_filepath (str) : absolute/relative path to edges.csv file\n",
    "        tweets_filepath (str) : absolute/relative path to tweets.csv file\n",
    "    Output:\n",
    "        (pd.DataFrame, pd.DataFrame, pd.DataFrame) : A tuple of three dataframes, the first one for users,\n",
    "                                                    the second for edges and the third for tweets.\n",
    "    \"\"\"\n",
    "    \n",
    "    users_frame = pd.read_csv(users_filepath)\n",
    "    edges_frame = pd.read_csv(edges_filepath)\n",
    "    tweets_frame = pd.read_csv(tweets_filepath)\n",
    "\n",
    "    return (users_frame, edges_frame,tweets_frame)\n",
    "\n",
    "def main():\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "\n",
    "    x, y, z =load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath)\n",
    "    print(type(x.friends_count))\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your function using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOLAB_IGNORE_START\n",
    "(users_df, edges_df, tweets_df) = load_twitter_data_pandas('users.csv', 'edges.csv', 'tweets.csv')\n",
    "# make sure to change the path to csv files appropriately\n",
    "# print (users_df.head())\n",
    "# print (edges_df.head())\n",
    "# print (tweets_df.head())\n",
    "# # AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task B: Correlation [4pts + 3pts]\n",
    "Statisticians and data analysts usually like to study about correlation between different observed variables. This helps uncover interesting patterns in the data such as causal relationships (e.g., snow on the road leads to increase in number of accidents). Correlation studies are important for multiple reasons:\n",
    "- While [correlation does not imply causation](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation), a lack of correlation implies a lack of causation. This can be used to rule out many causal relationships.\n",
    "- Correlation helps with prediction. The more closely related two variables are, the easier it is to predict one from the other.\n",
    "\n",
    "In this task, we ask you to plot the friends_count (on y-axis) vs the followers_count (on x-axis) using the matplotlib package. [Here](http://matplotlib.org/examples/shapes_and_collections/scatter_demo.html) is an example to get started with scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEJCAYAAABR4cpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHMZJREFUeJzt3X90XOV95/H3lQSEgi0LDzISdgJN7CbY20L45RRySkIWDMkJpKHfQjfBaSlONk2WLMk6TpvWLNAcFU5Dfc4GJyZhMU0P5Ju0WbwHO4YYSIDF4ATMqZ0Q18VObEu2kC3LxoYaa+7+ca+k0WikuTNXo5FmPq9zdDT3uT+eZx6P9Z3nx31uEIYhIiIiaTRUuwAiIjL1KZiIiEhqCiYiIpKagomIiKSmYCIiIqkpmIiISGoKJiIikpqCiYiIpKZgIiIiqTVVuwATSLf6i4iUJyh2QD0FEzo7O8s6L5PJ0NPTM86lmXpUDxHVQ0T1EKn1emhvb090nLq5REQkNQUTERFJTcFERERSUzAREZHUFExERCQ1BRMREUlNwWSchH29ZDc9TdjXW+2iiIhMuLq6z6RSwr5esnctg+4uwtY2GpZ2EDS3VLtYIiITRi2TcRBu2wLdXdFGdxfhtq3VLZCIyARTMBkHwbwF0NoWbbS2EcybX90CiYhMMHVzjYOguYWGpR2E27YSzJuvLi4RqTsKJuMkaG4huPDSahdDRKQq1M0lIiKpKZiIiEhqCiYiIpKagomIiKSmYCIiIqkpmIiISGoKJiIikpqCiYiIpKZgIiIiqSmYiIhIagomIiKSWtG1ucxsDvAgMAsIgVXuvsLMTgO+B5wF7ATM3XvNLABWAFcDR4FPufuL8bUWA1+NL32nu6+O088HHgBOBtYCt7h7WE4eIiIy8ZK0TI4DX3T3c4CFwF+Y2TnAMmCDu88FNsTbAFcBc+OfJcBKgDgwLAcuBi4ClpvZwPK6K4Gbc85bFKeXlIeIiFRH0WDi7l0D3/rd/TDwS+BM4BpgdXzYauDa+PU1wIPuHrr7RmCGmbUBVwKPu/sBd+8FHgcWxfumu/tGdw+JWkG51yolDxERqYKSlqA3s7OA84DngVnuHj9ekL1E3WAQBZpdOaftjtPGSt9dIJ0y8ujKScPMlhC1XHB3MplMwnc6XFNTU9nn1hLVQ0T1EFE9RFQPkcTBxMxOBf4Z+IK7HzKzwX3x+EZYgfKlysPdVwGr4s2wp6enrLwzmQzlnltLVA8R1UNE9RCp9Xpob29PdFyi2VxmdgJRIPknd/+XOHnfQNdS/Ls7Tt8DzMk5fXacNlb67ALp5eQhIiJVUDSYxDOnvgP80t2/nrNrDbA4fr0YeCQn/UYzC8xsIdAXd1WtB64ws5Z44P0KYH2875CZLYzzujHvWqXkISIiVZCkm+sS4JPAv5rZ5jjtL4EOwM3sJuDXwEC/11qiKbvbiabt/imAux8wszuATfFxt7v7gfj1ZxmaGrwu/qHUPEREpDqCMKzoUMdkEnZ2dpZ1Yq33iSaleoioHiKqh0it10M8ZhIUO053wIuISGoKJiIikpqCiYiIpKZgIiIiqSmYiIhIagomIiKSmoKJiIikpmAiIiKpKZiIiEhqCiYiIpKagomIiKSmYCIiIqkpmIiISGoKJiIikpqCiYiIpKZgIiIiqSmYiIhIagomIiKSmoKJiIikpmAiIiKpKZiIiEhqCiYiIpKagomIiKSmYCIiIqkpmIiISGoKJiIikpqCiYiIpKZgIiIiqSmYiIhIagomIiKSmoKJiIikpmAiIiKpKZhMEmFfL9lNTxP29Va7KCIiJWuqdgEkDiR3LYPuLsLWNhqWdhA0t1S7WCIiiallMgmE27ZAd1e00d1FuG1rdQskIlIiBZNJIJi3AFrboo3WNoJ586tbIBGREhXt5jKz+4GPAN3uviBOuw24GXgtPuwv3X1tvO8rwE1AP/Df3H19nL4IWAE0At929444/WzgYWAm8HPgk+5+zMxOAh4Ezgf2A3/s7jvHymOqCppbaFjaQbhtK8G8+eriEpEpJ0nL5AFgUYH0e9z93PhnIJCcA1wPzI/PudfMGs2sEfgGcBVwDnBDfCzA38XXehfQSxQkiH/3xun3xMeNmkdpb3vyCZpbaLjwUgUSEZmSigYTd/8pcCDh9a4BHnb3/3D3HcB24KL4Z7u7v+rux4haIteYWQB8EPhBfP5q4Nqca62OX/8AuDw+frQ8RESkStLM5vqcmd0I/Az4orv3AmcCG3OO2R2nAezKS7+YqGvroLsfL3D8mQPnuPtxM+uLjx8rj2HMbAmwJL4GmUymjLcJTU1NZZ9bS1QPEdVDRPUQUT1Eyg0mK4E7gDD+/ffAn41XocaLu68CVsWbYU9PT1nXyWQylHtuLVE9RFQPEdVDpNbrob29PdFxZc3mcvd97t7v7lngPoa6mfYAc3IOnR2njZa+H5hhZk156cOuFe9vjo8f7VoiIlIlZQUTM2vL2fwYsCV+vQa43sxOimdpzQVeADYBc83sbDM7kWgAfY27h8CTwHXx+YuBR3KutTh+fR3wRHz8aHmIiEiVJJka/BBwGZAxs93AcuAyMzuXqJtrJ/BpAHffamYO/AI4DvyFu/fH1/kcsJ5oavD97j5wZ96XgYfN7E7gJeA7cfp3gH80s+1EEwCuL5aHiIhURxCGYbXLMFHCzs7Osk6s9T7RpFQPEdVDRPUQqfV6iMdMgmLH6Q54ERFJTcFERERSUzAREZHUFExERCQ1BRMREUlNwURERFJTMBERkdQUTEREJDUFExERSU3BREREUlMwERGR1BRMREQkNQUTERFJTcFERERSUzAREZHUFEzKEPb1kt30NGFfb7WLIiIyKRR90qIMF/b1kr1rGXR3Eba20bC0g6C5pdrFEhGpKrVMShRu2wLdXdFGdxfhtq1jnyAiUgcUTEoUzFsArW3RRmsbwbz51S2QiMgkoG6uEgXNLTQs7SDctpVg3nx1cYmIoGBSlqC5heDCS6tdDBGRSUPdXCIikpqCiYiIpKZgIiIiqSmYiIhIagomIiKSmoJJibSUiojISJoaXAItpSIiUphaJiXQUioiIoUpmJRAS6mIiBSmbq4SaCkVEZHCFExKpKVURERGUjeXiIikpmAiIiKpKZiIiEhqCiYiIpJa0QF4M7sf+AjQ7e4L4rTTgO8BZwE7AXP3XjMLgBXA1cBR4FPu/mJ8zmLgq/Fl73T31XH6+cADwMnAWuAWdw/LyUNERKojScvkAWBRXtoyYIO7zwU2xNsAVwFz458lwEoYDD7LgYuBi4DlZjYwr3YlcHPOeYvKyUNERKqnaDBx958CB/KSrwFWx69XA9fmpD/o7qG7bwRmmFkbcCXwuLsfcPde4HFgUbxvurtvdPcQeDDvWqXkISIiVVLufSaz3D1eV4S9wKz49ZnArpzjdsdpY6XvLpBeTh5d5DGzJUStF9ydTCaT8O0N19TUVPa5tUT1EFE9RFQPEdVDJPVNi/H4RjgehRnvPNx9FbAq3gx7enrKyj+TyVDuubVE9RBRPURUD5Far4f29vZEx5U7m2vfQNdS/Ls7Tt8DzMk5bnacNlb67ALp5eQhIiJVUm4wWQMsjl8vBh7JSb/RzAIzWwj0xV1V64ErzKwlHni/Algf7ztkZgvjWVo35l2rlDwmJT3/RETqQZKpwQ8BlwEZM9tNNCurA3Azuwn4NWDx4WuJpuxuJ5q2+6cA7n7AzO4ANsXH3e7uA4P6n2VoavC6+IdS85iM9PwTEakXQRhWdLhjMgk7OzvLOrHcPtHspqcJV909uB0sWUrDFF4kstb7hpNSPURUD5Far4d4zCQodpzugK8gPf9EROqFlqCvID3/RETqhYJJhen5JyJSD9TNJSIiqSmYlEDTfEVEClM3V0Ka5isiMjq1TBIKt22B7vjeyO4uwm1bq1sgEZFJRMEkIU3zFREZnbq5EtI0XxGR0SmYlEDTfEVEClM3l4iIpKZgUiJNDxYRGUndXCXQ9GARkcLUMimBpgeLiBSmYFICTQ8WESlM3Vwl0PRgEZHCFExKpOnBIiIjqZtLRERSUzAREZHUFExERCQ1BZMK0I2NIlJvNAA/znRjo4jUI7VMxplubBSReqRgMs50Y6OI1CN1c40z3dgoIvVILZOEShlUD5pbaLjwUgUSkSlKk2hKp5ZJAv29+zWoLlInNImmPGqZJHBs60saVBepE5pEUx4FkwROnH+eBtVF6oQm0ZRH3VwJNLbMpGFpB9nNz1e7KCJSYZpEUx4Fk1I89kPo7iL72A/VjypSw7Q6eOnUzZWQ+lFFREanYJKQ+lFFREanbq6EguYWgs8sI3z2xwSXfEhdXCIiOdQySSjs6yX8Zgds+L+E3+wgu2tHopuadPOTiNSDVC0TM9sJHAb6gePufoGZnQZ8DzgL2AmYu/eaWQCsAK4GjgKfcvcX4+ssBr4aX/ZOd18dp58PPACcDKwFbnH3cLQ80ryXYkaMmdyzHA4fHPOmJt38JCL1YjxaJh9w93Pd/YJ4exmwwd3nAhvibYCrgLnxzxJgJUAcGJYDFwMXAcvNbOAv7krg5pzzFhXJo2KGjZlMnwGHD0avxxiM16C9iNSLSnRzXQOsjl+vBq7NSX/Q3UN33wjMMLM24ErgcXc/ELcuHgcWxfumu/tGdw+BB/OuVSiPihmYex4sWUrwhf+ZaDBeg/YiUi/SDsCHwGNmFgLfcvdVwCx3j7+OsxeYFb8+E9iVc+7uOG2s9N0F0hkjj4rKnXseJripSTc/iUi9SBtMLnX3PWbWCjxuZq/k7ozHN8KUeYxprDzMbAlRlxruTiaTKSuPpqamkedmMvDOucVPTnrcFFCwHuqQ6iGieoioHiKpgom774l/d5vZD4nGPPaZWZu7d8VdVd3x4XuAOTmnz47T9gCX5aU/FafPLnA8Y+SRX75VwKp4M+zp6SnrfWYyGco9t5aoHiKqh4jqIVLr9dDe3p7ouLLHTMzsFDObNvAauALYAqwBFseHLQYeiV+vAW40s8DMFgJ9cVfVeuAKM2uJB96vANbH+w6Z2cJ4JtiNedcqlIeIiFRBmgH4WcAzZvYy8ALwqLv/COgA/rOZ/RvwoXgboqm9rwLbgfuAzwK4+wHgDmBT/HN7nEZ8zLfjc/4dWBenj5ZHRemeERGRwoIwrOiQxmQSdnZ2lnViJpOh+6VNhPf8DRzugzq9Z6TWm/NJqR4iqodIrddD3M0VFDtOd8An0N+7n/AflkeBBHTPiIhIHgWTBI5tfQkOHRxKCBrgjDNHP0FEpM4omCRw4vzzYFrzUEKYhb17Rj9BRKTOKJgk0Ngyk+C/3x4towK6m11EJI+WoE+oYc7ZhH+zQnezi4gUoGBSAj3KU0SkMHVziYhIagomCWV37aD/4fvI7tpR7aKIiEw6CiYJvLVzO+Gdt0ZPWbzzVgUUEZE8CiYJHHn0+5Dtjzay/YRPPFrdAomITDIKJgk0tc8ZnjAr2SqaIiL1QsEkgZPOWxjd9Q7R73e8Uws+iojk0NTgBI7v3hnd9Q7R7/v+nvDwQcI6XfBRRCZG2NdLuG0LwbwFk/7vjFomCZw4/7yhZ7lPnwGH43W6tOCjiFRI2NdL9q5lhKvujn5P8p4QtUySuuJjAAS//TuE3+yA7i4tqyIiFRNu2xL9nYHBL66T+aZpBZMiwr5eDty1LPpHndlK8JW7CZZ2aFkVEamoYN4Cwta2KfPFVcGkiOzmjUPfDvZ3k33uSRre9wGgbh4qJiJVEDS30DCFvrgqmBSV94Cxdd8n+5N10LNPA/AiUlFTaT1ADcAX0XDuxXDKtKGEo0egZ1/0WgPwIiKAgklCozz++LTTCY8envSzLEREKk3BpIhw2xY4cqjwzjePwndXDk7bC/t6dTOjiNQljZkUc8ZsaGyE/v6R+44eiX53d5Hd/Dw89sOo60tjKSJSZ9QyKWbv7sKB5JRTYWZr9Hrghsa8OeEiIvVCLZNizpgNQQBh3lTgT3+Zhva3Ry0S4psZx5gTPpWWRRARKZWCSTF7d48MJEDw+uHoRU7XVvCZZbB3z4g54QPLIqgLTERqlbq5ighPnT4yccZMgnnzRyx3wN49NFx46YhAUWhZBBGRWqJgUswLPx11VzBvwdB4yRjLHSQ9TqTWaIZj/VA3VzFvHRuZdnA/2c3P0/gHixItdzAeyyJozEWmGnXv1hcFk2J+9a+F03t76P/Jj4CQhnMXFv1PkmZZBP2nlKloqq16K+mom6uYQi0TgCfXwnfvjW5avO3zZHftqFgRRhtzUReCTGbq3q0vapkU058tnH709aHXrx8ivGc54fIVAOPeHVVoKWq1VmSym2qr3ko6CibFZI8nO+7wweF3wc9shauuo+Hci0fO7ipx/KPQf8rspqfVhSCT3lRa9VbSUTdXMcdG6ebK19oGbxwZ9uwTvnsv2dtvGdYFVu6jOIPmlmHTjtWFMHmou1FELZP0TjkVPnZjdAf8vV8buf/QwcEusKC5ZdwGJdWFMDmou1EkopZJGg2N8Okv0/gHiwhffWXoOScAJ5089PrwwaEbFc+YDdNnRK9TtijyWysy8XRDqkhEwSSNbD/8r7+l/2fPwI/+ZSi9ZSac/FtD2zNbBwfNw292wKGDMG0GwWeWVTQQqPul8tTdOJw+c/VrSndzmdkiYAXQCHzb3TsmvBDH3oRv3TU87cSTYF/n0PZV140cND98EPbugTlnA8UH5UsdtFf3y8RQd+MQfebq25RtmZhZI/AN4CrgHOAGMztnPPPo/8J/SX5wQ+PQ69xAEjQMfXPN7eKa2Uq4fx/9P1lH/8+eIfvX/zUalO9YSv9P1g37Zhf29ZLtWDq4P8m3vuzm56dE90stfJPN7W6shfdTLnX51bep3DK5CNju7q8CmNnDwDXAL8YthyOHkx+bLfDME4AwC1//a0bs3d8N/7x65PE9+6IbIb+7Ek4+BWaeDqdOGxqP6dlH9mtfgt//APy/J+B4P0xrjh7UdfoZMPc98OYb8PRjQ9cMAsKXn6d/f3f0dMg9v4ETTyRY9HGC6TOiPwJnzCbc+iLs64KL3k/w+qGoCwcG97/xymb6wwBeeBpmtdHwvg9Gb33zRnjj6EBmcPJvjZgSHfb1RgHujSPD3+9T62B/9+Cqy+GrvyJ/VYGwr5fsc0/Arh1RSy4zC575MVz5MRrf83vDqzuvBZfdtYPw2R8TXPIhGuJWYBKlthQH39+6Hwy+n6TfzAvlNdHL5wyWP+GKDoUUuh8qP4/8OquVJYIm83uZqLIFYYHl1acCM7sOWOTufx5vfxK42N0/N8opYWdn5yi7Cuu/+aPpCjnZNTTAjNPgQE/UggrzbtCc2Ro9y6VnX+GnTTa3ROkHekZeOzOLhmV3Df2h7Vg6fIJCIdOa4XDfYN4NX7kbIAqeB14rfM6tdwwGlNxuFlrb4BOfhRW3ReVubCT4q68nCij518kPCi2NAT3Llgz90fzMsmgsbOBbeSxYspSGIjP1CuUFjJn/eBvx7xPXfbE8M5kMPT3D/+2jP1wju/zy3+ewOpviXWL5n4fJ9F6KfZaTaG9vBwiKHTeVWyZFmdkSYAmAu5PJZEo6v8ifvqkvmx0KBPmBBKLW04BCT5scqyunZx+ndv2Gk985lzde2cyhIoEkaD6NsO/AsLxP7foNEHJotEACnPDUo5z2/ssBonxyullOeOpR3hood38/b3vxWaafd+GY5Sh0nYH3MeDYc08O685528+f5Y28QNLYNpuWhe+nsWVmyXlBOGb+423Ev09c98XybGpqGvl/KpOBAuflv8+3vfjMUJ1NwHuspPzPw2R6L8U+y+NpKgeTPcCcnO3Zcdogd18FrIo3w/xvUXWvwi2T19vezpGeHsK2d0RdU4UCymmnw9V/BL/9O3Dv14Z9O3697e1Dx4wSUN667MOD347DtndELZL4W9hbl30YXt402DJ5872XcCzBZyD/OgPvY0DLu3932P43z78EBiZXZGbBoo8Tnnsxvf0hFMmvUF7AmPmPtxH/PnHdF8uzUMtkzDxy6+y9l8ILz0zYe6yk/M/DZHovxT7LScQtk6KmcjdXE7ANuJwoiGwC/sTdRxv1K7mbCyrY1XXKdDhyaGi76QQ44cRoID/MRmMgp0yLphm/+z9B82lwcD/8ags0NcGC84aPmbxxBE5vg3e9O7pe30GCD36YcN8eeOShaCyltT0eM9kFJ51IcOUfxmMmW+GMMwm3vhRNHrjo/QSvHx7s8x7YP+3IIQ6FxGMm7TS87wNAPNg/OGZCkTGT0Y8b6rdnZPpzT+aMmbTCMxvgymtHGTPJWXZm1w7CZzcQXHJ5GWMmhWdoZTIZXvv3fxu2f6zjy8krzfXKMVrdj6WUYDKQx3jV2WRS6PMwmaSt56TdXFM2mACY2dXAPxBNDb7f3f92jMPLCiZQ+n+aWqV6iKgeIqqHSK3XQ12Mmbj7WmBttcshIlLvpux9JiIiMnkomIiISGoKJiIikpqCiYiIpKZgIiIiqU3pqcElqps3KiIyzopODa6nlklQ7o+Z/TzN+bXyo3pQPage6rYeiqqnYCIiIhWiYCIiIqkpmCSzqvghdUH1EFE9RFQPEdUD1NUAvIiIVIhaJiIiktqUXuhxvJnZImAF0SrE33b3jrz9JwEPAucD+4E/dvedE13OSktQD7cCfw4cB14D/szdfz3hBa2wYvWQc9zHgR8AF7r7zyawiBWXpA7MzIDbiKbfv+zufzKhhZwACf5PvB1YDcyIj1kWL0RbN9QyiZlZI/AN4CrgHOAGMzsn77CbgF53fxdwD/B3E1vKyktYDy8BF7j77xL9Eb1rYktZeQnrATObBtwCPD+xJay8JHVgZnOBrwCXuPt84AsTXtAKS/hZ+Crg7n4ecD1w78SWsvoUTIZcBGx391fd/RjwMHBN3jHXEH37gOiP6OVmlmgO9hRStB7c/Ul3H3jK1Uaip1zWmiSfB4A7iL5UvDmRhZsgSergZuAb7t4L4O7d1J4k9RAC0+PXzUB5D0+awhRMhpwJ7MrZ3h2nFTzG3Y8DfcDYD/meepLUQ66bgHUVLVF1FK0HM3svMMfdH53Igk2gJJ+FecA8M3vWzDbG3UG1Jkk93AZ8wsx2Ez1j6fMTU7TJQ8FEymZmnwAuAO6udlkmmpk1AF8HvljtslRZEzAXuAy4AbjPzGZUtUTVcQPwgLvPBq4G/jH+jNSNunqzRewB5uRsz47TCh4TP4O+mWggvpYkqQfM7EPAXwEfdff/mKCyTaRi9TANWAA8ZWY7gYXAGjO7YMJKWHlJPgu7gTXu/pa77wC2EQWXWpKkHm4CHMDdnwPeBmQmpHSThGZzDdkEzDWzs4k+KNcD+bNS1gCLgeeA64An3L3WbtQpWg9mdh7wLWBRjfaRQ5F6cPc+cv5YmNlTwJdqbDZXkv8T/4foW/n/NrMMUbfXqxNayspLUg+/AS4HHjCz9xAFk9cmtJRVppZJLB4D+RywHvhllORbzex2M/tofNh3gJlmth24FVhWndJWTsJ6uBs4Ffi+mW02szVVKm7FJKyHmpawDtYD+83sF8CTwP9w95pqrSeshy8CN5vZy8BDwKdq8IvmmHQHvIiIpKaWiYiIpKZgIiIiqSmYiIhIagomIiKSmqYGi4jUIDO7H/gI0O3uC4ocm3qhSrVMRERq0wNA0uVtUi9UqZaJiEgNcvefmtlZuWlm9k6iFZBPB44CN7v7K4zDQpVqmYiI1I9VwOfd/XzgSwy1QG4j5UKVCiYiInXAzE4Ffp945QqiJZHa4t2pF6pUN5eISH1oAA66+7kF9t1EPL7i7s+Z2cBClYnX3lPLRESkDrj7IWCHmf0RgJkFZvZ78e6BhSopd6FKrc0lIlKDzOwhoufMZIB9wHLgCWAlUffWCcDD7n57/Bji+4gWcA2Bpe7+WCn5KZiIiEhq6uYSEZHUFExERCQ1BRMREUlNwURERFJTMBERkdQUTEREJDUFExERSU3BREREUvv/UTFMWLWrDNkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_friends_vs_followers(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (matplotlib.collections.PathCollection) : The object returned by the scatter plot function\n",
    "    \"\"\"\n",
    "    return plt.scatter(users_df.followers_count, users_df.friends_count, s=10)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "    users_df, _, _  =load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath)\n",
    "    #print(len(users_df.followers_count))\n",
    "    plot_friends_vs_followers(users_df)\n",
    "\n",
    "\n",
    "main()\n",
    "# # AUTOLAB_IGNORE_START\n",
    "# p = plot_friends_vs_followers(users_df)\n",
    "# plt.show()\n",
    "# # AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a correlation between these two variables from your scatter plot? Let's measure this quantitatively using the [Pearson's correlation coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient). \n",
    "\n",
    "For a set of observations $(X,Y) = [(x_1,y_1), (x_2,y_2), ... , (x_n,y_n)]$, the Pearson's correlation coefficient is a measure of the linear dependence between two variables $X$ and $Y$, giving a value between +1 and −1 inclusive, where 1 is total positive correlation, 0 is no correlation, and −1 is total negative correlation.\n",
    "\n",
    "$r=r_{xy}={\\frac {n\\sum x_{i}y_{i}-\\sum x_{i}\\sum y_{i}}{{\\sqrt {n\\sum x_{i}^{2}-(\\sum x_{i})^{2}}}~{\\sqrt {n\\sum y_{i}^{2}-(\\sum y_{i})^{2}}}}}$\n",
    "\n",
    "Now, fill in the following function to compute the Pearson's correlation coefficient between friends_count and followers_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.096678820583905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in long_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:34: RuntimeWarning: overflow encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "def correlation_coefficient(users_df):\n",
    "    \"\"\" Plots the friends_count (on y-axis) against the followers_count (on x-axis).\n",
    "    Input:\n",
    "        users_df (pd.DataFrame) : Dataframe containing Twitter user attributes,\n",
    "                                    as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (double) : correlation coefficient between friends_count and followers_count\n",
    "    \"\"\"\n",
    "    xi = users_df.friends_count\n",
    "#     print(xi)\n",
    "    xi_sum = np.sum(xi)\n",
    "\n",
    "\n",
    "    yi = users_df.followers_count\n",
    "    yi_sum = np.sum(yi)\n",
    "    \n",
    "    xi_times_yi = xi * yi\n",
    "\n",
    "\n",
    "    sum_xi_times_yi = np.sum(xi_times_yi)\n",
    "    \n",
    "    n = len(xi)\n",
    "    n2 = len(yi)\n",
    "    xi_sq = xi * xi\n",
    "    yi_sq = yi * yi\n",
    "    \n",
    "    sum_xi_sq = np.sum(xi_sq)\n",
    "    sq_xi_sum = xi_sum * xi_sum\n",
    "    \n",
    "    sum_yi_sq = np.sum(yi_sq)\n",
    "    sq_yi_sum = yi_sum * yi_sum    \n",
    "    \n",
    "    numrtr = (n * sum_xi_times_yi) - (xi_sum * yi_sum)\n",
    "    denom = (np.sqrt((n * sum_xi_sq) - (sq_xi_sum))) * (np.sqrt((n * sum_yi_sq) - (sq_yi_sum)))\n",
    "    if denom != 0:\n",
    "        return numrtr/denom\n",
    "    else:\n",
    "        return -1\n",
    "def main():\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/users.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edges.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweets.csv\"\n",
    "    users_df, _, _  =load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath)\n",
    "    \n",
    "    cof = correlation_coefficient(users_df)\n",
    "    print(cof)\n",
    "    \n",
    "    \n",
    "# AUTOLAB_IGNORE_START\n",
    "print (correlation_coefficient(users_df))\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Task C: Degree distribution [4pts]\n",
    "If you are not familiar with graph theory and/or graph mining, skip the first paragraph.\n",
    "\n",
    "As you're familiar with graphs, you might know that the degree of a node is the number of connections it has to other nodes. A common statistic to look out for in the case of real world graphs is the degree distribution. Literature says degrees of nodes in real world graphs follow a [power law distribution](https://en.wikipedia.org/wiki/Power_law). The implication is that a scatter plot of num_users versus k (as we will define below) yields an almost straight line. In this task, we shall verify whether the given crawl of Twitter network satisfies this property.\n",
    "\n",
    "Let us call the number of friends a Twitter user has as his/her degree. The degree distribution is a histogram of the number of friends. Your task is to visualize this histogram. Use the default number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution(edges_df):\n",
    "    \"\"\" Plots the distribution of .\n",
    "    Input:\n",
    "        edges_df (pd.DataFrame) : Dataframe containing Twitter edges,\n",
    "                        as returned by load_twitter_data_pandas()\n",
    "    Output:\n",
    "        (array, array, list of Patch objects) : Tuple of the values of the histogram bins, \n",
    "                        the edges of the bins and the silent list of individual patches used to create the histogram.\n",
    "    \"\"\"\n",
    "    return plt.hist(edges_df.screen_name)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    users_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/usersCopy.csv\"\n",
    "    edges_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/edgesCopy.csv\"\n",
    "    tweets_filepath = \"/Users/hamzaliaqet/Downloads/ML_PATH/15388/hw2/tweetsCopy.csv\"\n",
    "    _, edges_df, _  = load_twitter_data_pandas(users_filepath, edges_filepath, tweets_filepath)\n",
    "    plt.hist(edges_df)\n",
    "    \n",
    "    \n",
    "main()\n",
    "# AUTOLAB_IGNORE_START\n",
    "#degree_distribution(edges_df)\n",
    "# AUTOLAB_IGNORE_STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any surprising/unexpected pattern? What can you say about the way in which the Twitter data was collected?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
